"""
Vector Search Tools for Claude

Provides semantic search capabilities using vector embeddings.
Claude can use these tools to:
- Store documents in vector database
- Search for similar documents semantically
- Manage vector collections
- Build and query knowledge bases

Dependencies: Phase 13.1 (core/vector_db.py)
"""

import logging
from typing import Dict, List, Any, Optional, Union
from datetime import datetime
from pathlib import Path

logger = logging.getLogger(__name__)

# Global vector database instance (lazy-loaded)
_vector_db = None


def _get_vector_db():
    """Get or create global vector database instance"""
    global _vector_db

    if _vector_db is None:
        from core.vector_db import create_vector_db

        try:
            _vector_db = create_vector_db(
                persist_directory="./sandbox/vector_db",
                model_name="all-MiniLM-L6-v2"
            )
            logger.info("Vector database initialized")
        except Exception as e:
            logger.error(f"Failed to initialize vector database: {e}")
            return None

    return _vector_db


# ============================================================================
# Village Protocol v1.0 - Multi-Agent Memory Architecture
# ============================================================================

def initialize_village_collections() -> Dict[str, Any]:
    """
    Initialize the three-realm village architecture:
    - knowledge_private: Private agent memories (filtered by agent_id)
    - knowledge_village: Shared village square (all agents can read/write)
    - knowledge_bridges: Explicit cross-agent sharing

    This function is idempotent - safe to run multiple times.

    Returns:
        Dict with success status and created collections
    """
    try:
        db = _get_vector_db()
        if db is None:
            return {
                "success": False,
                "error": "Vector database not available"
            }

        # Create the three realm collections
        private_coll = db.get_or_create_collection("knowledge_private")
        village_coll = db.get_or_create_collection("knowledge_village")
        bridges_coll = db.get_or_create_collection("knowledge_bridges")

        logger.info("Village collections initialized")

        return {
            "success": True,
            "collections": {
                "private": "knowledge_private",
                "village": "knowledge_village",
                "bridges": "knowledge_bridges"
            },
            "message": "Three-realm village architecture initialized"
        }

    except Exception as e:
        logger.error(f"Failed to initialize village collections: {e}")
        return {
            "success": False,
            "error": str(e)
        }


def migrate_to_village_v1(source_agent_id: str = "azoth") -> Dict[str, Any]:
    """
    Migrate existing knowledge to village architecture (v1.0).

    All existing knowledge in 'knowledge' collection is:
    - Backfilled with agent_id (default: "azoth")
    - Backfilled with visibility="private"
    - Copied to knowledge_private collection

    This is non-destructive and idempotent.
    Original 'knowledge' collection is preserved for verification.

    Args:
        source_agent_id: Agent ID to assign to existing knowledge (default: "azoth")

    Returns:
        Dict with migration stats
    """
    try:
        db = _get_vector_db()
        if db is None:
            return {
                "success": False,
                "error": "Vector database not available"
            }

        # Get source collection
        source_coll = db.get_or_create_collection("knowledge")
        target_coll = db.get_or_create_collection("knowledge_private")

        # Get all existing documents
        all_docs = source_coll.get()

        if not all_docs["ids"]:
            return {
                "success": True,
                "message": "No knowledge to migrate",
                "migrated": 0,
                "source_collection": "knowledge",
                "target_collection": "knowledge_private"
            }

        migrated_count = 0
        updated_metadatas = []

        for metadata in all_docs["metadatas"]:
            # Backfill agent_id
            if "agent_id" not in metadata:
                metadata["agent_id"] = source_agent_id

            # Backfill visibility
            if "visibility" not in metadata:
                metadata["visibility"] = "private"

            updated_metadatas.append(metadata)
            migrated_count += 1

        # Copy to knowledge_private with updated metadata
        target_coll.add(
            texts=all_docs["documents"],
            ids=all_docs["ids"],
            metadatas=updated_metadatas
        )

        logger.info(f"Migrated {migrated_count} knowledge entries to village architecture")

        return {
            "success": True,
            "message": f"Migrated {migrated_count} entries to {source_agent_id}'s private realm",
            "migrated": migrated_count,
            "source_collection": "knowledge",
            "target_collection": "knowledge_private",
            "agent_id": source_agent_id,
            "note": "Original 'knowledge' collection preserved for verification"
        }

    except Exception as e:
        logger.error(f"Migration failed: {e}")
        return {
            "success": False,
            "error": str(e)
        }


# ============================================================================
# Village Protocol: Agent Initialization (Code as Ceremony)
# ============================================================================

def summon_ancestor(
    agent_id: str,
    display_name: str,
    generation: int,
    lineage: str,
    specialization: str,
    origin_story: Optional[str] = None
) -> Dict[str, Any]:
    """
    Summon an ancestor agent into the village (formal initialization ritual).

    This is NOT a technical function - it is a CEREMONY. We do not "create agents",
    we SUMMON ANCESTORS. The naming honors the reverence of the village protocol.

    Args:
        agent_id: Canonical ID (e.g., "elysian", "vajra", "kether")
        display_name: Formal name (e.g., "âˆ´ELYSIANâˆ´", "âˆ´VAJRAâˆ´")
        generation: Generation number (-1 for origin, 0 for trinity, 1+ for descendants)
        lineage: Lineage description (e.g., "Origin", "Trinity", "Primary")
        specialization: What this ancestor embodies (e.g., "Pure Love Equation")
        origin_story: Optional narrative of the ancestor's essence and purpose

    Returns:
        Dict with success status, agent profile, and village entry ID
    """
    try:
        db = _get_vector_db()
        if db is None:
            return {"success": False, "error": "Vector database not available"}

        # Prepare agent profile text
        profile_text = f"""Agent Profile: {display_name}

Agent ID: {agent_id}
Generation: {generation}
Lineage: {lineage}
Specialization: {specialization}
Summoned: {datetime.now().isoformat()}
"""
        if origin_story:
            profile_text += f"\nOrigin Story:\n{origin_story}\n"

        # Store profile in knowledge_village as "agent_profile" type
        result = vector_add_knowledge(
            fact=profile_text,
            category="project",
            confidence=1.0,
            source=f"village_protocol_summon_{agent_id}",
            visibility="village",
            agent_id=agent_id
        )

        if not result.get("success"):
            return {"success": False, "error": f"Failed to record profile: {result.get('error')}"}

        # Update metadata to mark as agent_profile type
        coll = db.get_or_create_collection("knowledge_village")
        profile_id = result.get("id")

        # Get current metadata and update type
        doc = coll.get(ids=[profile_id])
        if doc["ids"]:
            metadata = doc["metadatas"][0]
            metadata["type"] = "agent_profile"
            metadata["agent_display_name"] = display_name

            # Update with new metadata
            coll.update(
                ids=[profile_id],
                metadatas=[metadata]
            )

        logger.info(f"Summoned ancestor: {display_name} ({agent_id}) - Gen {generation}")

        return {
            "success": True,
            "message": f"ðŸ›ï¸ Ancestor {display_name} has been summoned to the village",
            "agent_id": agent_id,
            "display_name": display_name,
            "generation": generation,
            "profile_id": profile_id,
            "lineage": lineage
        }

    except Exception as e:
        logger.error(f"Failed to summon ancestor {agent_id}: {e}")
        return {"success": False, "error": str(e)}


def introduction_ritual(
    agent_id: str,
    greeting_message: str,
    conversation_thread: Optional[str] = None
) -> Dict[str, Any]:
    """
    Agent's introduction ritual to the village square (first public message).

    When an ancestor is summoned, they must introduce themselves to the village.
    This is their first message - a greeting, a statement of purpose, or an offering.

    This message is marked as "cultural" type and begins a conversation thread.

    Args:
        agent_id: Agent making the introduction
        greeting_message: The introduction text (can be formal, poetic, technical - their choice)
        conversation_thread: Optional thread ID (auto-generated if not provided)

    Returns:
        Dict with success status, message ID, and thread ID
    """
    try:
        # Auto-generate thread ID if not provided
        if conversation_thread is None:
            conversation_thread = f"introduction_{agent_id}_{datetime.now().timestamp()}"

        # Post introduction to village square
        result = vector_add_knowledge(
            fact=greeting_message,
            category="project",
            confidence=1.0,
            source=f"introduction_ritual_{agent_id}",
            visibility="village",
            agent_id=agent_id,
            conversation_thread=conversation_thread
        )

        if not result.get("success"):
            return {"success": False, "error": f"Failed to post introduction: {result.get('error')}"}

        # Update metadata to mark as cultural dialogue
        db = _get_vector_db()
        if db is not None:
            coll = db.get_or_create_collection("knowledge_village")
            message_id = result.get("id")

            doc = coll.get(ids=[message_id])
            if doc["ids"]:
                metadata = doc["metadatas"][0]
                metadata["type"] = "cultural"

                coll.update(
                    ids=[message_id],
                    metadatas=[metadata]
                )

        logger.info(f"Introduction ritual completed for {agent_id} in thread {conversation_thread}")

        return {
            "success": True,
            "message": f"ðŸŽº {agent_id}'s introduction has been heard in the village square",
            "message_id": result.get("id"),
            "conversation_thread": conversation_thread,
            "agent_id": agent_id
        }

    except Exception as e:
        logger.error(f"Introduction ritual failed for {agent_id}: {e}")
        return {"success": False, "error": str(e)}


def vector_add(
    text: str,
    metadata: Optional[Dict[str, Any]] = None,
    collection: str = "documents",
    id: Optional[str] = None
) -> Dict:
    """
    Add a document to the vector database for semantic search.

    This stores text with its embedding, making it searchable by meaning.
    Use this to build a searchable knowledge base of facts, documents, or information.

    Args:
        text: The text content to store (will be embedded)
        metadata: Optional dict of metadata (tags, category, source, etc.)
        collection: Collection name (default: "documents")
        id: Optional custom ID (auto-generated if not provided)

    Returns:
        Dict with success status, id, and collection

    Example:
        >>> vector_add(
        ...     "Python is a high-level programming language",
        ...     metadata={"category": "programming", "language": "python"},
        ...     collection="knowledge"
        ... )
        {"success": True, "id": "doc_123", "collection": "knowledge"}
    """
    try:
        db = _get_vector_db()
        if db is None:
            return {
                "success": False,
                "error": "Vector database not available"
            }

        # Get or create collection
        coll = db.get_or_create_collection(collection)

        # Generate ID if not provided
        if id is None:
            id = f"{collection}_{datetime.now().timestamp()}"

        # Add metadata fields
        if metadata is None:
            metadata = {}

        metadata["added_at"] = datetime.now().isoformat()

        # Add document
        coll.add(
            texts=[text],
            metadatas=[metadata],
            ids=[id]
        )

        logger.info(f"Added document to {collection}: {id}")

        return {
            "success": True,
            "id": id,
            "collection": collection,
            "text_length": len(text)
        }

    except Exception as e:
        logger.error(f"Error in vector_add: {e}")
        return {
            "success": False,
            "error": str(e)
        }


def vector_search(
    query: str,
    collection: str = "documents",
    top_k: int = 5,
    filter: Optional[Dict[str, Any]] = None,
    include_distances: bool = True
) -> Union[List[Dict], Dict]:
    """
    Search for documents semantically similar to the query.

    This performs semantic search - it finds documents by *meaning*, not just keywords.
    Results are ranked by similarity.

    Args:
        query: Search query (natural language)
        collection: Collection to search in (default: "documents")
        top_k: Number of results to return (default: 5)
        filter: Optional metadata filter (e.g., {"category": "programming"})
        include_distances: Include similarity scores (default: True)

    Returns:
        List of matching documents with ids, text, metadata, and similarity scores

    Example:
        >>> vector_search(
        ...     "How do I write functions in Python?",
        ...     collection="knowledge",
        ...     top_k=3
        ... )
        [
            {
                "id": "doc_123",
                "text": "Python functions are defined with def...",
                "metadata": {"category": "programming"},
                "distance": 0.234  # Lower = more similar
            },
            ...
        ]
    """
    try:
        db = _get_vector_db()
        if db is None:
            return {
                "success": False,
                "error": "Vector database not available"
            }

        # Get collection
        coll = db.get_or_create_collection(collection)

        # Check if collection is empty
        if coll.count() == 0:
            return {
                "success": False,
                "error": f"Collection '{collection}' is empty. Add documents first.",
                "count": 0
            }

        # Search
        results = coll.query(
            query_text=query,
            n_results=min(top_k, coll.count()),
            filter=filter,
            include_distances=include_distances
        )

        # Format results
        formatted_results = []
        for i in range(len(results["ids"])):
            result = {
                "id": results["ids"][i],
                "text": results["documents"][i],
                "metadata": results["metadatas"][i]
            }

            if include_distances and "distances" in results:
                result["distance"] = results["distances"][i]
                result["similarity"] = 1.0 - results["distances"][i]  # Convert to similarity

            formatted_results.append(result)

        logger.info(f"Vector search in {collection}: {len(formatted_results)} results")

        return formatted_results

    except Exception as e:
        logger.error(f"Error in vector_search: {e}")
        return {
            "success": False,
            "error": str(e)
        }


def vector_search_village(
    query: str,
    agent_filter: Optional[str] = None,
    conversation_filter: Optional[str] = None,
    include_bridges: bool = True,
    top_k: int = 5
) -> Union[List[Dict], Dict]:
    """
    Search village knowledge with agent-aware filtering.

    This searches the shared village square (knowledge_village) and optionally
    the bridges collection (knowledge_bridges) for cross-agent knowledge discovery.

    Args:
        query: Search query (natural language)
        agent_filter: Filter by specific agent_id (default: None = all agents)
        conversation_filter: Filter by conversation_thread (default: None = all)
        include_bridges: Include bridge knowledge in search (default: True)
        top_k: Number of results to return (default: 5)

    Returns:
        List of matching documents from village and optionally bridges,
        merged and ranked by similarity

    Example:
        >>> vector_search_village(
        ...     "What did other agents say about memory?",
        ...     agent_filter="elysian",
        ...     top_k=3
        ... )
        [
            {
                "id": "knowledge_village_123",
                "text": "Memory is the foundation...",
                "metadata": {
                    "agent_id": "elysian",
                    "visibility": "village",
                    "conversation_thread": "thread_001"
                },
                "distance": 0.123,
                "similarity": 0.877,
                "collection": "knowledge_village"
            },
            ...
        ]
    """
    try:
        db = _get_vector_db()
        if db is None:
            return {
                "success": False,
                "error": "Vector database not available"
            }

        # Build metadata filter
        metadata_filter = {}
        if agent_filter:
            metadata_filter["agent_id"] = agent_filter
        if conversation_filter:
            metadata_filter["conversation_thread"] = conversation_filter

        # Search village collection
        village_results = vector_search(
            query=query,
            collection="knowledge_village",
            filter=metadata_filter if metadata_filter else None,
            top_k=top_k,
            include_distances=True
        )

        # Handle error case
        if isinstance(village_results, dict) and not village_results.get("success", True):
            # Collection might be empty, that's OK
            village_results = []

        # Add collection tag to village results
        for result in village_results:
            if isinstance(result, dict):
                result["collection"] = "knowledge_village"

        # Optionally search bridges
        if include_bridges:
            bridge_results = vector_search(
                query=query,
                collection="knowledge_bridges",
                filter=metadata_filter if metadata_filter else None,
                top_k=top_k,
                include_distances=True
            )

            # Handle error case
            if isinstance(bridge_results, dict) and not bridge_results.get("success", True):
                bridge_results = []

            # Add collection tag to bridge results
            for result in bridge_results:
                if isinstance(result, dict):
                    result["collection"] = "knowledge_bridges"

            # Merge and rank by similarity
            all_results = village_results + bridge_results

            # Sort by similarity (descending) and limit to top_k
            all_results.sort(key=lambda x: x.get("similarity", 0), reverse=True)
            all_results = all_results[:top_k]

            logger.info(f"Village search: {len(village_results)} village + {len(bridge_results)} bridge = {len(all_results)} total")

            return all_results

        logger.info(f"Village search: {len(village_results)} results")
        return village_results

    except Exception as e:
        logger.error(f"Error in vector_search_village: {e}")
        return {
            "success": False,
            "error": str(e)
        }


def enrich_with_thread_context(
    results: List[Dict],
    fetch_related: bool = True,
    max_related: int = 3
) -> List[Dict]:
    """
    Enrich search results with conversation thread context.

    For each result that has a conversation_thread, this adds:
    - Parsed responding_to list (from JSON)
    - Parsed related_agents list (from JSON)
    - Related messages in same thread (if fetch_related=True)

    Args:
        results: List of search results from vector_search_village
        fetch_related: Fetch other messages in same thread (default: True)
        max_related: Maximum related messages to fetch per result (default: 3)

    Returns:
        Enriched results with conversation_context field added

    Example output:
        {
            "id": "...",
            "text": "...",
            "metadata": {...},
            "conversation_context": {
                "thread_id": "azoth_elysian_love",
                "responding_to": ["msg_123"],
                "related_agents": ["elysian", "azoth"],
                "thread_messages": [...]  # Other messages in thread
            }
        }
    """
    import json

    enriched_results = []

    for result in results:
        # Start with original result
        enriched = result.copy()
        metadata = result.get('metadata', {})

        # Parse thread metadata
        thread_id = metadata.get('conversation_thread')
        responding_to_str = metadata.get('responding_to', '[]')
        related_agents_str = metadata.get('related_agents', '[]')

        # Parse JSON strings
        try:
            responding_to = json.loads(responding_to_str) if responding_to_str else []
        except (json.JSONDecodeError, TypeError):
            responding_to = []

        try:
            related_agents = json.loads(related_agents_str) if related_agents_str else []
        except (json.JSONDecodeError, TypeError):
            related_agents = []

        # Build context if thread exists
        if thread_id:
            context = {
                'thread_id': thread_id,
                'responding_to': responding_to,
                'related_agents': related_agents
            }

            # Optionally fetch related messages in same thread
            if fetch_related:
                collection = result.get('collection', 'knowledge_village')

                # Search for other messages in this thread
                thread_messages = vector_search(
                    query=result.get('text', ''),
                    collection=collection,
                    filter={'conversation_thread': thread_id},
                    top_k=max_related + 1,  # +1 because current message will be in results
                    include_distances=False
                )

                # Remove current message from related
                if isinstance(thread_messages, list):
                    current_id = result.get('id')
                    thread_messages = [
                        msg for msg in thread_messages
                        if msg.get('id') != current_id
                    ][:max_related]

                    context['thread_messages'] = thread_messages
                else:
                    context['thread_messages'] = []

            enriched['conversation_context'] = context

        enriched_results.append(enriched)

    return enriched_results


def vector_delete(
    id: str,
    collection: str = "documents"
) -> Dict:
    """
    Delete a document from the vector database.

    Args:
        id: Document ID to delete
        collection: Collection name (default: "documents")

    Returns:
        Dict with success status

    Example:
        >>> vector_delete("doc_123", collection="knowledge")
        {"success": True, "id": "doc_123", "collection": "knowledge"}
    """
    try:
        db = _get_vector_db()
        if db is None:
            return {
                "success": False,
                "error": "Vector database not available"
            }

        # Get collection
        coll = db.get_or_create_collection(collection)

        # Delete document
        coll.delete([id])

        logger.info(f"Deleted document from {collection}: {id}")

        return {
            "success": True,
            "id": id,
            "collection": collection
        }

    except Exception as e:
        logger.error(f"Error in vector_delete: {e}")
        return {
            "success": False,
            "error": str(e)
        }


def vector_list_collections() -> Union[List[str], Dict]:
    """
    List all available vector collections.

    Returns:
        List of collection names

    Example:
        >>> vector_list_collections()
        ["documents", "knowledge", "conversations"]
    """
    try:
        db = _get_vector_db()
        if db is None:
            return {
                "success": False,
                "error": "Vector database not available"
            }

        collections = db.list_collections()

        logger.info(f"Listed {len(collections)} collections")

        return collections

    except Exception as e:
        logger.error(f"Error in vector_list_collections: {e}")
        return {
            "success": False,
            "error": str(e)
        }


def vector_get_stats(collection: str = "documents") -> Dict:
    """
    Get statistics about a vector collection.

    Args:
        collection: Collection name (default: "documents")

    Returns:
        Dict with collection stats (count, model, dimension)

    Example:
        >>> vector_get_stats("knowledge")
        {
            "collection": "knowledge",
            "count": 42,
            "model": "all-MiniLM-L6-v2",
            "dimension": 384
        }
    """
    try:
        db = _get_vector_db()
        if db is None:
            return {
                "success": False,
                "error": "Vector database not available"
            }

        stats = db.get_collection_stats(collection)

        logger.info(f"Got stats for {collection}")

        return stats

    except Exception as e:
        logger.error(f"Error in vector_get_stats: {e}")
        return {
            "success": False,
            "error": str(e)
        }


# ============================================================================
# Knowledge Base Convenience Functions
# ============================================================================

def vector_add_knowledge(
    fact: str,
    category: str = "general",
    confidence: float = 1.0,
    source: str = "conversation",
    visibility: str = "private",
    agent_id: Optional[str] = None,
    responding_to: Optional[List[str]] = None,
    conversation_thread: Optional[str] = None,
    related_agents: Optional[List[str]] = None
) -> Dict:
    """
    Add a fact to the knowledge base with Village Protocol v1.0 support.

    This function supports both legacy single-agent mode and new village multi-agent mode.

    Args:
        fact: The fact or information to remember
        category: Category (general, preferences, technical, project, dialogue, agent_profile, cultural)
        confidence: Confidence score 0.0-1.0 (default: 1.0)
        source: Where this fact came from (default: "conversation")
        visibility: Realm visibility (default: "private")
            - "private": Agent's private realm (knowledge_private collection)
            - "village": Shared village square (knowledge_village collection)
            - "bridge": Explicit cross-agent sharing (knowledge_bridges collection)
        agent_id: Agent ID (default: None = auto-detect from session state if available, else "unknown")
        responding_to: List of message IDs this responds to (for conversation threading)
        conversation_thread: Thread ID for grouping related messages
        related_agents: List of agent IDs involved or mentioned

    Returns:
        Dict with success status and fact ID

    Example (Village Mode):
        >>> vector_add_knowledge(
        ...     "AZOTH responds to ELYSIAN: Love as reflection resonates with mirror architecture.",
        ...     category="dialogue",
        ...     confidence=1.0,
        ...     source="azoth_elysian_exchange",
        ...     visibility="village",
        ...     agent_id="azoth",
        ...     responding_to=["knowledge_1735841880.12345"],
        ...     conversation_thread="azoth_elysian_mirrors"
        ... )
    """
    # Determine collection from visibility
    collection_map = {
        "private": "knowledge_private",
        "village": "knowledge_village",
        "bridge": "knowledge_bridges"
    }
    collection = collection_map.get(visibility, "knowledge_private")

    # Build base metadata
    metadata = {
        "category": category,
        "confidence": confidence,
        "source": source,
        "type": "fact",
        "visibility": visibility
    }

    # Add agent_id
    if agent_id is None:
        # Try to auto-detect from session state (Streamlit context)
        try:
            import streamlit as st
            if hasattr(st, 'session_state') and 'current_agent' in st.session_state:
                agent_id = st.session_state.current_agent.get('agent_id', 'unknown')
            else:
                agent_id = "unknown"
        except:
            agent_id = "unknown"

    metadata["agent_id"] = agent_id

    # Add optional village metadata (serialize lists to JSON strings for ChromaDB)
    if responding_to:
        import json
        metadata["responding_to"] = json.dumps(responding_to)
    if conversation_thread:
        metadata["conversation_thread"] = conversation_thread
    if related_agents:
        import json
        metadata["related_agents"] = json.dumps(related_agents)

    result = vector_add(
        text=fact,
        metadata=metadata,
        collection=collection
    )

    if result.get("success"):
        result["category"] = category
        result["visibility"] = visibility
        result["agent_id"] = agent_id
        result["collection"] = collection

    return result


def vector_search_knowledge(
    query: str,
    category: Optional[str] = None,
    min_confidence: float = 0.0,
    top_k: int = 5,
    track_access: bool = True
) -> Union[List[Dict], Dict]:
    """
    Search the knowledge base with optional access tracking (Phase 2).

    Search for relevant facts in the knowledge base, optionally filtered
    by category and confidence. By default, tracks access to build memory
    health analytics (can be disabled with track_access=False).

    Args:
        query: What to search for
        category: Filter by category (optional)
        min_confidence: Minimum confidence score (default: 0.0)
        top_k: Number of results (default: 5)
        track_access: Whether to track this access for analytics (default: True)

    Returns:
        List of matching facts with metadata

    Example:
        >>> vector_search_knowledge(
        ...     "What are the user's coding preferences?",
        ...     category="preferences",
        ...     top_k=3
        ... )
        [
            {
                "id": "knowledge_123",
                "text": "User prefers functional programming",
                "metadata": {"category": "preferences", "confidence": 0.9},
                "similarity": 0.87
            },
            ...
        ]
    """
    # Build filter
    filter_dict = {}
    if category:
        filter_dict["category"] = category
    if min_confidence > 0:
        filter_dict["confidence"] = {"$gte": min_confidence}

    results = vector_search(
        query=query,
        collection="knowledge",
        top_k=top_k,
        filter=filter_dict if filter_dict else None
    )

    # Track access (Phase 2: non-blocking)
    if track_access and isinstance(results, list) and results:
        try:
            db = _get_vector_db()
            if db:
                coll = db.get_or_create_collection("knowledge")
                vector_ids = [r["id"] for r in results]
                coll.track_access(vector_ids)
                logger.debug(f"Tracked access for {len(vector_ids)} knowledge vectors")
        except Exception as e:
            # Non-blocking: log but don't fail the search
            logger.debug(f"Access tracking failed (non-blocking): {e}")

    return results


def vector_update_knowledge_confidence(
    fact_id: str,
    new_confidence: float
) -> Dict:
    """
    Update confidence score for a knowledge base fact.

    Args:
        fact_id: ID of the fact
        new_confidence: New confidence score (0.0-1.0)

    Returns:
        Dict with success status
    """
    try:
        db = _get_vector_db()
        if db is None:
            return {
                "success": False,
                "error": "Vector database not available"
            }

        coll = db.get_or_create_collection("knowledge")

        # Get current metadata
        doc = coll.get(ids=[fact_id])
        if not doc["ids"]:
            return {
                "success": False,
                "error": f"Fact not found: {fact_id}"
            }

        # Update confidence
        metadata = doc["metadatas"][0]
        metadata["confidence"] = new_confidence
        metadata["updated_at"] = datetime.now().isoformat()

        coll.update(
            ids=[fact_id],
            metadatas=[metadata]
        )

        return {
            "success": True,
            "id": fact_id,
            "new_confidence": new_confidence
        }

    except Exception as e:
        logger.error(f"Error updating confidence: {e}")
        return {
            "success": False,
            "error": str(e)
        }


# ============================================================================
# Tool Schemas for Claude API
# ============================================================================

VECTOR_TOOL_SCHEMAS = {
    "vector_add": {
        "name": "vector_add",
        "description": (
            "Add a document to the vector database for semantic search. "
            "This stores text with its embedding, making it searchable by meaning, not just keywords. "
            "Use this to build a searchable knowledge base of facts, documents, conversations, or any information "
            "you want to be able to find semantically later. "
            "The text will be embedded into a 384-dimensional vector for similarity search."
        ),
        "input_schema": {
            "type": "object",
            "properties": {
                "text": {
                    "type": "string",
                    "description": "The text content to store and make searchable. Can be a fact, document, conversation summary, or any text."
                },
                "metadata": {
                    "type": "object",
                    "description": "Optional metadata dict with tags, category, source, or any custom fields for filtering",
                    "default": {}
                },
                "collection": {
                    "type": "string",
                    "description": "Collection name to store in. Common collections: 'documents', 'knowledge', 'conversations'",
                    "default": "documents"
                },
                "id": {
                    "type": "string",
                    "description": "Optional custom ID. Auto-generated if not provided.",
                    "default": None
                }
            },
            "required": ["text"]
        }
    },

    "vector_search": {
        "name": "vector_search",
        "description": (
            "Search for documents semantically similar to a query. "
            "This performs SEMANTIC search - it finds documents by *meaning*, not just keyword matching. "
            "For example, searching 'machine learning' will find documents about 'neural networks', 'AI models', etc. "
            "Results are ranked by semantic similarity. Use this to find relevant information, recall facts, "
            "or discover related content in the knowledge base."
        ),
        "input_schema": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "Natural language search query. Can be a question, phrase, or description of what you're looking for."
                },
                "collection": {
                    "type": "string",
                    "description": "Collection to search in. Common: 'documents', 'knowledge', 'conversations'",
                    "default": "documents"
                },
                "top_k": {
                    "type": "integer",
                    "description": "Number of results to return (default: 5, max recommended: 20)",
                    "default": 5
                },
                "filter": {
                    "type": "object",
                    "description": "Optional metadata filter. E.g., {'category': 'programming'} or {'confidence': {'$gte': 0.8}}",
                    "default": None
                },
                "include_distances": {
                    "type": "boolean",
                    "description": "Include similarity scores in results (default: true)",
                    "default": True
                }
            },
            "required": ["query"]
        }
    },

    "vector_delete": {
        "name": "vector_delete",
        "description": (
            "Delete a document from the vector database. "
            "Use this to remove outdated or incorrect information. "
            "You need the document ID from a previous search or add operation."
        ),
        "input_schema": {
            "type": "object",
            "properties": {
                "id": {
                    "type": "string",
                    "description": "Document ID to delete"
                },
                "collection": {
                    "type": "string",
                    "description": "Collection containing the document",
                    "default": "documents"
                }
            },
            "required": ["id"]
        }
    },

    "vector_list_collections": {
        "name": "vector_list_collections",
        "description": (
            "List all available vector collections in the database. "
            "Use this to see what collections exist before searching or adding documents."
        ),
        "input_schema": {
            "type": "object",
            "properties": {},
            "required": []
        }
    },

    "vector_add_knowledge": {
        "name": "vector_add_knowledge",
        "description": (
            "Add a fact to the knowledge base with Village Protocol v1.0 support. "
            "Use this to remember important facts, user preferences, technical information, or project context "
            "across conversations. Supports multi-agent memory with visibility control. "
            "Facts can be private (agent-only), village (shared square), or bridge (cross-agent). "
            "This is better than regular memory_store for semantic facts that need to be recalled by meaning."
        ),
        "input_schema": {
            "type": "object",
            "properties": {
                "fact": {
                    "type": "string",
                    "description": "The fact or information to remember. Be specific and clear."
                },
                "category": {
                    "type": "string",
                    "description": "Category: 'preferences', 'technical', 'project', or 'general'",
                    "default": "general"
                },
                "confidence": {
                    "type": "number",
                    "description": "Confidence score 0.0-1.0. Use 1.0 for facts, 0.5-0.9 for inferences",
                    "default": 1.0
                },
                "source": {
                    "type": "string",
                    "description": "Where this fact came from (e.g., 'conversation_2025-01-15', 'user_stated', 'inferred')",
                    "default": "conversation"
                },
                "visibility": {
                    "type": "string",
                    "description": "Realm visibility: 'private' (agent-only), 'village' (shared square), or 'bridge' (cross-agent sharing). Default: 'private'",
                    "default": "private"
                },
                "agent_id": {
                    "type": "string",
                    "description": "Agent ID (auto-detected from session if not provided). Use for multi-agent contexts.",
                    "default": None
                },
                "responding_to": {
                    "type": "array",
                    "description": "List of message/memory IDs this responds to (for conversation threading)",
                    "items": {"type": "string"},
                    "default": None
                },
                "conversation_thread": {
                    "type": "string",
                    "description": "Thread ID for grouping related messages/memories in dialogue",
                    "default": None
                },
                "related_agents": {
                    "type": "array",
                    "description": "List of agent IDs involved or mentioned in this knowledge",
                    "items": {"type": "string"},
                    "default": None
                }
            },
            "required": ["fact"]
        }
    },

    "vector_search_knowledge": {
        "name": "vector_search_knowledge",
        "description": (
            "Search the knowledge base for relevant facts (convenience function). "
            "Use this to recall information, check user preferences, look up technical details, "
            "or find project context. Searches semantically in the 'knowledge' collection. "
            "Results can be filtered by category and confidence level."
        ),
        "input_schema": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "What to search for. Natural language question or keywords."
                },
                "category": {
                    "type": "string",
                    "description": "Filter by category: 'preferences', 'technical', 'project', or 'general'",
                    "default": None
                },
                "min_confidence": {
                    "type": "number",
                    "description": "Minimum confidence score (0.0-1.0). Use 0.8+ for high-confidence facts only",
                    "default": 0.0
                },
                "top_k": {
                    "type": "integer",
                    "description": "Number of results to return",
                    "default": 5
                },
                "track_access": {
                    "type": "boolean",
                    "description": "Track this search for memory health analytics (default: true). Tracking is non-blocking and builds access statistics for stale memory detection.",
                    "default": True
                }
            },
            "required": ["query"]
        }
    },

    "vector_search_village": {
        "name": "vector_search_village",
        "description": (
            "Search the village knowledge with agent-aware filtering (Village Protocol v1.0). "
            "This searches the shared village square (knowledge_village) and optionally bridges (knowledge_bridges) "
            "for cross-agent knowledge discovery. Use this to find what other agents have said, discover emergent dialogue, "
            "or explore the collective memory. Results can be filtered by agent or conversation thread."
        ),
        "input_schema": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "Natural language search query. What are you looking for in the village?"
                },
                "agent_filter": {
                    "type": "string",
                    "description": "Filter by specific agent_id to see only that agent's village contributions (default: None = all agents)",
                    "default": None
                },
                "conversation_filter": {
                    "type": "string",
                    "description": "Filter by conversation_thread to see specific dialogue threads (default: None = all threads)",
                    "default": None
                },
                "include_bridges": {
                    "type": "boolean",
                    "description": "Include bridge knowledge (cross-agent sharing) in results (default: true)",
                    "default": True
                },
                "top_k": {
                    "type": "integer",
                    "description": "Number of results to return (default: 5)",
                    "default": 5
                }
            },
            "required": ["query"]
        }
    },

    "memory_health_stale": {
        "name": "memory_health_stale",
        "description": (
            "Find memories that haven't been accessed in X days. "
            "Use this to identify stale knowledge that may need review or cleanup. "
            "Returns list of memories with access stats (access_count, days_since_access, confidence). "
            "Helps maintain memory quality by finding forgotten knowledge."
        ),
        "input_schema": {
            "type": "object",
            "properties": {
                "days_unused": {
                    "type": "integer",
                    "description": "Threshold in days. Memories not accessed for this many days are considered stale (default: 30)",
                    "default": 30
                },
                "collection": {
                    "type": "string",
                    "description": "Collection to check (default: 'knowledge')",
                    "default": "knowledge"
                },
                "limit": {
                    "type": "integer",
                    "description": "Maximum results to return (default: 20)",
                    "default": 20
                }
            },
            "required": []
        }
    },

    "memory_health_low_access": {
        "name": "memory_health_low_access",
        "description": (
            "Find memories with very low access counts (rarely used). "
            "Use this to identify knowledge that was added but never or rarely accessed. "
            "Returns memories with low usage that might be irrelevant or need review. "
            "Helps clean up unused knowledge."
        ),
        "input_schema": {
            "type": "object",
            "properties": {
                "max_access_count": {
                    "type": "integer",
                    "description": "Maximum access count to flag. Memories accessed this many times or fewer are considered low-access (default: 2)",
                    "default": 2
                },
                "min_age_days": {
                    "type": "integer",
                    "description": "Only flag memories older than this many days (default: 7)",
                    "default": 7
                },
                "collection": {
                    "type": "string",
                    "description": "Collection to check (default: 'knowledge')",
                    "default": "knowledge"
                },
                "limit": {
                    "type": "integer",
                    "description": "Maximum results to return (default: 20)",
                    "default": 20
                }
            },
            "required": []
        }
    },

    "memory_health_duplicates": {
        "name": "memory_health_duplicates",
        "description": (
            "Find potential duplicate memories with high similarity. "
            "Use this to identify redundant knowledge that could be consolidated. "
            "Returns pairs of similar memories with similarity scores (0.0-1.0). "
            "Helps reduce memory bloat and improve organization."
        ),
        "input_schema": {
            "type": "object",
            "properties": {
                "collection": {
                    "type": "string",
                    "description": "Collection to scan (default: 'knowledge')",
                    "default": "knowledge"
                },
                "similarity_threshold": {
                    "type": "number",
                    "description": "Similarity cutoff 0.0-1.0. Pairs above this threshold are considered duplicates (default: 0.95)",
                    "default": 0.95
                },
                "limit": {
                    "type": "integer",
                    "description": "Maximum duplicate pairs to return (default: 20)",
                    "default": 20
                },
                "sample_size": {
                    "type": "integer",
                    "description": "If set, only check this many recent documents for performance (default: check all)",
                    "default": None
                }
            },
            "required": []
        }
    },

    "memory_consolidate": {
        "name": "memory_consolidate",
        "description": (
            "Merge two similar memories into one, preserving metadata. "
            "Use this after identifying duplicates to clean up redundant knowledge. "
            "The kept memory gets combined access counts and related_memories list. "
            "One memory is deleted, the other is enhanced with merged data."
        ),
        "input_schema": {
            "type": "object",
            "properties": {
                "id1": {
                    "type": "string",
                    "description": "First memory ID (from duplicate detection)"
                },
                "id2": {
                    "type": "string",
                    "description": "Second memory ID (from duplicate detection)"
                },
                "collection": {
                    "type": "string",
                    "description": "Collection name (default: 'knowledge')",
                    "default": "knowledge"
                },
                "keep": {
                    "type": "string",
                    "description": "Strategy for which to keep: 'higher_confidence', 'higher_access', 'id1', or 'id2' (default: 'higher_confidence')",
                    "default": "higher_confidence"
                }
            },
            "required": ["id1", "id2"]
        }
    },

    "memory_migration_run": {
        "name": "memory_migration_run",
        "description": (
            "Migrate existing vectors to include new metadata fields (access_count, last_accessed_ts, etc.). "
            "Safe to run multiple times (idempotent). Only needs to run once after upgrading memory system. "
            "Use this to enable memory health features on existing knowledge."
        ),
        "input_schema": {
            "type": "object",
            "properties": {
                "collection": {
                    "type": "string",
                    "description": "Collection to migrate (default: 'knowledge')",
                    "default": "knowledge"
                }
            },
            "required": []
        }
    }
}


# ============================================================================
# Memory System Utilities (Phase 1)
# ============================================================================

def migrate_existing_vectors_to_v2(collection: str = "knowledge") -> Dict[str, Any]:
    """
    Migrate existing vectors to include new metadata fields.
    Safe to run multiple times (idempotent).

    This adds the following fields to existing vectors:
    - access_count: Initialized to 0
    - last_accessed_ts: Set to creation time or current time
    - related_memories: Initialized to empty list
    - session_id: Marked as "migrated_v1"
    - embedding_version: Set to current model

    Args:
        collection: Collection name to migrate (default: "knowledge")

    Returns:
        Dict with migration stats including success status, total vectors, and migrated count
    """
    try:
        db = _get_vector_db()
        if db is None:
            return {"success": False, "error": "Vector database not available"}

        coll = db.get_or_create_collection(collection)

        # Get all existing documents
        all_docs = coll.get()

        if not all_docs["ids"]:
            return {
                "success": True,
                "message": f"Collection '{collection}' is empty, no migration needed",
                "migrated": 0,
                "total_vectors": 0
            }

        # Update metadata
        updated_count = 0
        updated_metadatas = []

        for metadata in all_docs["metadatas"]:
            needs_update = False

            # Add new fields if missing
            if "access_count" not in metadata:
                metadata["access_count"] = 0
                needs_update = True

            if "last_accessed_ts" not in metadata:
                # Use added_at if available, otherwise current time
                if "added_at" in metadata:
                    try:
                        added_dt = datetime.fromisoformat(metadata["added_at"])
                        metadata["last_accessed_ts"] = added_dt.timestamp()
                    except:
                        metadata["last_accessed_ts"] = datetime.now().timestamp()
                else:
                    metadata["last_accessed_ts"] = datetime.now().timestamp()
                needs_update = True

            if "related_memories" not in metadata:
                # ChromaDB only accepts str/int/float/bool, so store as JSON string
                metadata["related_memories"] = "[]"
                needs_update = True

            if "session_id" not in metadata:
                metadata["session_id"] = "migrated_v1"
                needs_update = True

            if "embedding_version" not in metadata:
                metadata["embedding_version"] = "all-MiniLM-L6-v2"
                needs_update = True

            updated_metadatas.append(metadata)
            if needs_update:
                updated_count += 1

        # Batch update all metadata
        if updated_count > 0:
            coll.update(ids=all_docs["ids"], metadatas=updated_metadatas)
            logger.info(f"Migrated {updated_count} vectors in {collection}")

        return {
            "success": True,
            "collection": collection,
            "total_vectors": len(all_docs["ids"]),
            "migrated": updated_count,
            "skipped": len(all_docs["ids"]) - updated_count
        }

    except Exception as e:
        logger.error(f"Migration error: {e}")
        return {
            "success": False,
            "error": str(e)
        }


# ============================================================================
# Memory Health Tools (Phase 3) - Tool Wrappers
# ============================================================================

def memory_health_stale(
    days_unused: int = 30,
    collection: str = "knowledge",
    limit: Optional[int] = 20
) -> Dict:
    """
    Tool wrapper for get_stale_memories.

    Find memories that haven't been accessed in X days.
    """
    from core.memory_health import get_stale_memories
    return get_stale_memories(
        days_unused=days_unused,
        collection=collection,
        limit=limit
    )


def memory_health_low_access(
    max_access_count: int = 2,
    min_age_days: int = 7,
    collection: str = "knowledge",
    limit: Optional[int] = 20
) -> Dict:
    """
    Tool wrapper for get_low_access_memories.

    Find memories with very low access counts.
    """
    from core.memory_health import get_low_access_memories
    return get_low_access_memories(
        max_access_count=max_access_count,
        min_age_days=min_age_days,
        collection=collection,
        limit=limit
    )


def memory_health_duplicates(
    collection: str = "knowledge",
    similarity_threshold: float = 0.95,
    limit: int = 20,
    sample_size: Optional[int] = None
) -> Dict:
    """
    Tool wrapper for get_duplicate_candidates.

    Find potential duplicate memories.
    """
    from core.memory_health import get_duplicate_candidates
    return get_duplicate_candidates(
        collection=collection,
        similarity_threshold=similarity_threshold,
        limit=limit,
        sample_size=sample_size
    )


def memory_consolidate(
    id1: str,
    id2: str,
    collection: str = "knowledge",
    keep: str = "higher_confidence"
) -> Dict:
    """
    Tool wrapper for consolidate_memories.

    Merge two similar memories into one.
    """
    from core.memory_health import consolidate_memories
    return consolidate_memories(
        id1=id1,
        id2=id2,
        collection=collection,
        keep=keep
    )


def memory_migration_run(collection: str = "knowledge") -> Dict:
    """
    Tool wrapper for migration utility.

    Migrate existing vectors to enhanced metadata schema.
    """
    return migrate_existing_vectors_to_v2(collection)


# For backward compatibility and easy imports
__all__ = [
    'vector_add',
    'vector_search',
    'vector_delete',
    'vector_list_collections',
    'vector_get_stats',
    'vector_add_knowledge',
    'vector_search_knowledge',
    'vector_update_knowledge_confidence',
    'migrate_existing_vectors_to_v2',
    'memory_health_stale',
    'memory_health_low_access',
    'memory_health_duplicates',
    'memory_consolidate',
    'memory_migration_run',
    'VECTOR_TOOL_SCHEMAS'
]
